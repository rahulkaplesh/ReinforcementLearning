{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from pyeasyga.pyeasyga import GeneticAlgorithm\n",
    "from monitor import interact\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "env = gym.make('Taxi-v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just setting my limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = { 'epsilon' : [0.09, 0.19], 'gamma' : [0.5, 0.6], 'epsilonreducer' : [85, 100] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the genetic opereators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual(data):\n",
    "    paramsValue = {};\n",
    "    paramsValue['epsilon'] = round(random.uniform(data['epsilon'][0], data['epsilon'][1]), 5)\n",
    "    paramsValue['gamma'] = round(random.uniform(data['gamma'][0], data['gamma'][1]), 4)\n",
    "    paramsValue['epsilonreducer'] = round(random.uniform(data['epsilonreducer'][0], data['epsilonreducer'][1]), 2)\n",
    "    return paramsValue\n",
    "\n",
    "def fitness_function (individual, parameter):\n",
    "    agent = Agent(epsilon=individual['epsilon'], gamma=individual['gamma'], epsilonreducer=individual['epsilonreducer'])\n",
    "    avg_rewards, best_avg_reward = interact(env, agent)\n",
    "    return best_avg_reward \n",
    "\n",
    "def crossover_function(parent_1, parent_2):\n",
    "    num = random.choice([1, 2, 3])\n",
    "    child1 = {}\n",
    "    child2 = {}\n",
    "    if num == 1 :\n",
    "        child1['epsilon'] = parent_2['epsilon']\n",
    "        child2['epsilon'] = parent_1['epsilon']\n",
    "        child1['gamma'] = parent_2['gamma']\n",
    "        child2['gamma'] = parent_1['gamma']\n",
    "        child1['epsilonreducer'] = parent_1['epsilonreducer']\n",
    "        child2['epsilonreducer'] = parent_2['epsilonreducer']\n",
    "    elif num == 2:\n",
    "        child1['epsilon'] = parent_1['epsilon']\n",
    "        child2['epsilon'] = parent_2['epsilon']\n",
    "        child1['gamma'] = parent_2['gamma']\n",
    "        child2['gamma'] = parent_1['gamma']\n",
    "        child1['epsilonreducer'] = parent_2['epsilonreducer']\n",
    "        child2['epsilonreducer'] = parent_1['epsilonreducer']\n",
    "    elif num == 3:\n",
    "        child1['epsilon'] = parent_2['epsilon']\n",
    "        child2['epsilon'] = parent_1['epsilon']\n",
    "        child1['gamma'] = parent_1['gamma']\n",
    "        child2['gamma'] = parent_2['gamma']\n",
    "        child1['epsilonreducer'] = parent_2['epsilonreducer']\n",
    "        child2['epsilonreducer'] = parent_1['epsilonreducer']\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individual):\n",
    "    num = random.choice([1, 2, 3])\n",
    "    if num == 1:\n",
    "        individual['epsilon'] = round(random.uniform(data['epsilon'][0], data['epsilon'][1]), 5)\n",
    "    elif num == 2:\n",
    "        individual['gamma'] = round(random.uniform(data['gamma'][0], data['gamma'][1]), 4)\n",
    "    elif num == 3:\n",
    "        individual['epsilonreducer'] = round(random.uniform(data['epsilonreducer'][0], data['epsilonreducer'][1]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pyeasyga to probe using the genetic algorithm library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(data,\n",
    "                      population_size=20,\n",
    "                      generations=3,\n",
    "                      crossover_probability=0.3,\n",
    "                      mutation_probability=0.8,\n",
    "                      elitism=True,\n",
    "                      maximise_fitness=True)\n",
    "ga.fitness_function = fitness_function\n",
    "ga.create_individual = create_individual\n",
    "ga.crossover_function = crossover_function\n",
    "ga.mutate_function = mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentParams : Epsilon : 0.16954 : gamma : 0.5951 : epsilonreducer : 89.63\n",
      "Episode 20000/20000 || Best average reward 8.499\n",
      "\n",
      "AgentParams : Epsilon : 0.15345 : gamma : 0.5065 : epsilonreducer : 85.68\n",
      "Episode 20000/20000 || Best average reward 8.387\n",
      "\n",
      "AgentParams : Epsilon : 0.13838 : gamma : 0.5064 : epsilonreducer : 91.84\n",
      "Episode 20000/20000 || Best average reward 8.575\n",
      "\n",
      "AgentParams : Epsilon : 0.09484 : gamma : 0.5148 : epsilonreducer : 96.57\n",
      "Episode 20000/20000 || Best average reward 8.827\n",
      "\n",
      "AgentParams : Epsilon : 0.10486 : gamma : 0.5921 : epsilonreducer : 90.64\n",
      "Episode 20000/20000 || Best average reward 8.348\n",
      "\n",
      "AgentParams : Epsilon : 0.16787 : gamma : 0.5968 : epsilonreducer : 93.73\n",
      "Episode 20000/20000 || Best average reward 8.448\n",
      "\n",
      "AgentParams : Epsilon : 0.17804 : gamma : 0.5617 : epsilonreducer : 92.14\n",
      "Episode 20000/20000 || Best average reward 8.594\n",
      "\n",
      "AgentParams : Epsilon : 0.16233 : gamma : 0.5949 : epsilonreducer : 88.71\n",
      "Episode 20000/20000 || Best average reward 8.734\n",
      "\n",
      "AgentParams : Epsilon : 0.11475 : gamma : 0.546 : epsilonreducer : 99.73\n",
      "Episode 20000/20000 || Best average reward 8.613\n",
      "\n",
      "AgentParams : Epsilon : 0.09596 : gamma : 0.5688 : epsilonreducer : 89.68\n",
      "Episode 20000/20000 || Best average reward 8.497\n",
      "\n",
      "AgentParams : Epsilon : 0.15686 : gamma : 0.5467 : epsilonreducer : 89.54\n",
      "Episode 20000/20000 || Best average reward 8.838\n",
      "\n",
      "AgentParams : Epsilon : 0.18243 : gamma : 0.5496 : epsilonreducer : 92.04\n",
      "Episode 20000/20000 || Best average reward 8.733\n",
      "\n",
      "AgentParams : Epsilon : 0.12781 : gamma : 0.5059 : epsilonreducer : 85.52\n",
      "Episode 20000/20000 || Best average reward 8.642\n",
      "\n",
      "AgentParams : Epsilon : 0.15073 : gamma : 0.5826 : epsilonreducer : 87.74\n",
      "Episode 20000/20000 || Best average reward 8.775\n",
      "\n",
      "AgentParams : Epsilon : 0.15647 : gamma : 0.596 : epsilonreducer : 98.38\n",
      "Episode 20000/20000 || Best average reward 8.878\n",
      "\n",
      "AgentParams : Epsilon : 0.13906 : gamma : 0.5015 : epsilonreducer : 93.89\n",
      "Episode 20000/20000 || Best average reward 8.759\n",
      "\n",
      "AgentParams : Epsilon : 0.12753 : gamma : 0.5507 : epsilonreducer : 96.98\n",
      "Episode 20000/20000 || Best average reward 8.478\n",
      "\n",
      "AgentParams : Epsilon : 0.09129 : gamma : 0.5565 : epsilonreducer : 97.88\n",
      "Episode 20000/20000 || Best average reward 8.492\n",
      "\n",
      "AgentParams : Epsilon : 0.11038 : gamma : 0.554 : epsilonreducer : 90.53\n",
      "Episode 20000/20000 || Best average reward 8.836\n",
      "\n",
      "AgentParams : Epsilon : 0.14055 : gamma : 0.5877 : epsilonreducer : 88.6\n",
      "Episode 20000/20000 || Best average reward 8.721\n",
      "\n",
      "AgentParams : Epsilon : 0.15686 : gamma : 0.5467 : epsilonreducer : 89.54\n",
      "Episode 20000/20000 || Best average reward 8.691\n",
      "\n",
      "AgentParams : Epsilon : 0.09459 : gamma : 0.5496 : epsilonreducer : 91.84\n",
      "Episode 20000/20000 || Best average reward 8.428\n",
      "\n",
      "AgentParams : Epsilon : 0.13999 : gamma : 0.546 : epsilonreducer : 87.74\n",
      "Episode 20000/20000 || Best average reward 8.732\n",
      "\n",
      "AgentParams : Epsilon : 0.11475 : gamma : 0.5826 : epsilonreducer : 99.29\n",
      "Episode 20000/20000 || Best average reward 8.796\n",
      "\n",
      "AgentParams : Epsilon : 0.15975 : gamma : 0.554 : epsilonreducer : 90.53\n",
      "Episode 20000/20000 || Best average reward 8.777\n",
      "\n",
      "AgentParams : Epsilon : 0.13861 : gamma : 0.5496 : epsilonreducer : 92.04\n",
      "Episode 20000/20000 || Best average reward 8.758\n",
      "\n",
      "AgentParams : Epsilon : 0.09484 : gamma : 0.5148 : epsilonreducer : 86.72\n",
      "Episode 20000/20000 || Best average reward 8.867\n",
      "\n",
      "AgentParams : Epsilon : 0.13906 : gamma : 0.5688 : epsilonreducer : 93.89\n",
      "Episode 20000/20000 || Best average reward 8.457\n",
      "\n",
      "AgentParams : Epsilon : 0.1812 : gamma : 0.5148 : epsilonreducer : 96.57\n",
      "Episode 20000/20000 || Best average reward 8.713\n",
      "\n",
      "AgentParams : Epsilon : 0.12849 : gamma : 0.546 : epsilonreducer : 99.73\n",
      "Episode 20000/20000 || Best average reward 8.799\n",
      "\n",
      "AgentParams : Epsilon : 0.14018 : gamma : 0.546 : epsilonreducer : 88.6\n",
      "Episode 20000/20000 || Best average reward 8.967\n",
      "\n",
      "AgentParams : Epsilon : 0.11475 : gamma : 0.5767 : epsilonreducer : 99.73\n",
      "Episode 20000/20000 || Best average reward 8.733\n",
      "\n",
      "AgentParams : Epsilon : 0.15647 : gamma : 0.5866 : epsilonreducer : 98.38\n",
      "Episode 20000/20000 || Best average reward 8.376\n",
      "\n",
      "AgentParams : Epsilon : 0.09484 : gamma : 0.556 : epsilonreducer : 96.57\n",
      "Episode 20000/20000 || Best average reward 8.598\n",
      "\n",
      "AgentParams : Epsilon : 0.14055 : gamma : 0.5877 : epsilonreducer : 88.6\n",
      "Episode 20000/20000 || Best average reward 8.585\n",
      "\n",
      "AgentParams : Epsilon : 0.16954 : gamma : 0.5951 : epsilonreducer : 89.63\n",
      "Episode 20000/20000 || Best average reward 8.775\n",
      "\n",
      "AgentParams : Epsilon : 0.11038 : gamma : 0.5804 : epsilonreducer : 90.53\n",
      "Episode 20000/20000 || Best average reward 8.944\n",
      "\n",
      "AgentParams : Epsilon : 0.09446 : gamma : 0.5826 : epsilonreducer : 87.74\n",
      "Episode 20000/20000 || Best average reward 8.814\n",
      "\n",
      "AgentParams : Epsilon : 0.11772 : gamma : 0.5148 : epsilonreducer : 96.57\n",
      "Episode 20000/20000 || Best average reward 8.889\n",
      "\n",
      "AgentParams : Epsilon : 0.15592 : gamma : 0.5467 : epsilonreducer : 89.54\n",
      "Episode 20000/20000 || Best average reward 8.659\n",
      "\n",
      "AgentParams : Epsilon : 0.14018 : gamma : 0.546 : epsilonreducer : 88.6\n",
      "Episode 20000/20000 || Best average reward 8.689\n",
      "\n",
      "AgentParams : Epsilon : 0.13861 : gamma : 0.5496 : epsilonreducer : 91.64\n",
      "Episode 20000/20000 || Best average reward 8.627\n",
      "\n",
      "AgentParams : Epsilon : 0.11772 : gamma : 0.5148 : epsilonreducer : 88.26\n",
      "Episode 20000/20000 || Best average reward 8.757\n",
      "\n",
      "AgentParams : Epsilon : 0.11475 : gamma : 0.5691 : epsilonreducer : 99.73\n",
      "Episode 20000/20000 || Best average reward 8.648\n",
      "\n",
      "AgentParams : Epsilon : 0.09309 : gamma : 0.554 : epsilonreducer : 90.53\n",
      "Episode 20000/20000 || Best average reward 8.277\n",
      "\n",
      "AgentParams : Epsilon : 0.11772 : gamma : 0.5148 : epsilonreducer : 94.96\n",
      "Episode 20000/20000 || Best average reward 8.973\n",
      "\n",
      "AgentParams : Epsilon : 0.14055 : gamma : 0.5877 : epsilonreducer : 88.6\n",
      "Episode 20000/20000 || Best average reward 8.767\n",
      "\n",
      "AgentParams : Epsilon : 0.13861 : gamma : 0.5496 : epsilonreducer : 92.04\n",
      "Episode 20000/20000 || Best average reward 8.862\n",
      "\n",
      "AgentParams : Epsilon : 0.09446 : gamma : 0.5557 : epsilonreducer : 87.74\n",
      "Episode 20000/20000 || Best average reward 8.553\n",
      "\n",
      "AgentParams : Epsilon : 0.10949 : gamma : 0.5496 : epsilonreducer : 92.04\n",
      "Episode 20000/20000 || Best average reward 8.715\n",
      "\n",
      "AgentParams : Epsilon : 0.09446 : gamma : 0.5514 : epsilonreducer : 87.74\n",
      "Episode 20000/20000 || Best average reward 8.948\n",
      "\n",
      "AgentParams : Epsilon : 0.10623 : gamma : 0.5951 : epsilonreducer : 89.63\n",
      "Episode 20000/20000 || Best average reward 8.886\n",
      "\n",
      "AgentParams : Epsilon : 0.11038 : gamma : 0.5148 : epsilonreducer : 99.77\n",
      "Episode 20000/20000 || Best average reward 8.821\n",
      "\n",
      "AgentParams : Epsilon : 0.15363 : gamma : 0.5804 : epsilonreducer : 90.53\n",
      "Episode 20000/20000 || Best average reward 8.447\n",
      "\n",
      "AgentParams : Epsilon : 0.14018 : gamma : 0.546 : epsilonreducer : 88.6\n",
      "Episode 20000/20000 || Best average reward 8.821\n",
      "\n",
      "AgentParams : Epsilon : 0.14018 : gamma : 0.546 : epsilonreducer : 88.6\n",
      "Episode 20000/20000 || Best average reward 8.851\n",
      "\n",
      "AgentParams : Epsilon : 0.11038 : gamma : 0.5804 : epsilonreducer : 89.99\n",
      "Episode 20000/20000 || Best average reward 8.316\n",
      "\n",
      "AgentParams : Epsilon : 0.11357 : gamma : 0.5804 : epsilonreducer : 90.53\n",
      "Episode 20000/20000 || Best average reward 8.883\n",
      "\n",
      "AgentParams : Epsilon : 0.13221 : gamma : 0.5148 : epsilonreducer : 96.57\n",
      "Episode 20000/20000 || Best average reward 8.768\n",
      "\n",
      "AgentParams : Epsilon : 0.11475 : gamma : 0.5763 : epsilonreducer : 99.29\n",
      "Episode 20000/20000 || Best average reward 8.564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.97, {'epsilon': 0.11772, 'gamma': 0.5148, 'epsilonreducer': 94.96})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga.best_individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
